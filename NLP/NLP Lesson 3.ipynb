{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Natural Language Processing From Scratch</h1>\n",
    "<h2 align=\"center\">Bruno Gon√ßalves</h2>\n",
    "<h4 align=\"center\">bgoncalves@gmail.com</h4>\n",
    "<h4 align=\"center\">@bgoncalves</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3 - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import gzip\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by taking the simplest approach and simply counting positive and negative words. We'll use Hu and Liu's Lexicon from their 2004 KDD paper: https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.loadtxt('data/positive-words.txt', dtype='str', comments=';')\n",
    "neg = np.loadtxt('data/negative-words.txt', dtype='str', comments=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary and assign the valence to each positive and negative word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence = {}\n",
    "\n",
    "for word in pos:\n",
    "    valence[word.lower()] = 1\n",
    "    \n",
    "for word in neg:\n",
    "    valence[word.lower()] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the simple word extraction function we defined in Lesson I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_words(text):\n",
    "    temp = text.split() # Split the text on whitespace\n",
    "    text_words = []\n",
    "\n",
    "    for word in temp:\n",
    "        # Remove any punctuation characters present in the beginning of the word\n",
    "        while word[0] in string.punctuation:\n",
    "            word = word[1:]\n",
    "\n",
    "        # Remove any punctuation characters present in the end of the word\n",
    "        while word[-1] in string.punctuation:\n",
    "            word = word[:-1]\n",
    "\n",
    "        # Append this word into our list of words.\n",
    "        text_words.append(word.lower())\n",
    "        \n",
    "    return text_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That now we can use to define a sentiment measuring function that returns the valence of a sentence or piece of text. Notice that we use the valence directly from the dictionary instead of treating positive and negative words separatly. This will prove useful later on ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment(text, valence):\n",
    "    words = extract_words(text.lower())\n",
    "    \n",
    "    word_count = 0\n",
    "    score = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if word in valence:\n",
    "            score += valence[word]\n",
    "            word_count += 1\n",
    "            \n",
    "    return score/word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our simple code with some simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-0.3333333333333333\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "texts = [\"I'm very happy\",\n",
    "         \"The product is pretty annoying, and I hate it\",\n",
    "         \"I'm sad\",\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    print(sentiment(text, valence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit surprising. One might expect the second sentence to be negative, after all \"pretty annoying\" and \"hate\" sound pretty negative. However, since each word in taken by itself, regardless of context we end up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretty 1\n",
      "annoying -1\n",
      "hate -1\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(texts[1].lower())\n",
    "for word in words:\n",
    "    if word in valence:\n",
    "        print(word, valence[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see later how to handle cases like this, but the solution requires two changes to our current approach: non-uniform weights and modifier words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to define a dictionary of modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modifiers = {\n",
    "    \"very\": 1.5,\n",
    "    \"much\": 1.3,\n",
    "    \"not\": -1,\n",
    "    \"pretty\": 1.5,\n",
    "    \"somewhat\": 1.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to change our sentiment measuring function to take the modifiers into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_modified(text, valence, modifiers, verbose=False):\n",
    "    words = extract_words(text.lower())\n",
    "    \n",
    "    word_count = 0\n",
    "    score = 0\n",
    "    ngrams = [[]]\n",
    "    \n",
    "    # generate ngrams\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        \n",
    "        if word in modifiers:\n",
    "            ngrams[-1].append(word)\n",
    "            continue\n",
    "\n",
    "        if word in valence:\n",
    "            ngrams[-1].append(word)\n",
    "        else:\n",
    "            if len(ngrams[-1]) > 0:\n",
    "                ngrams.append([])\n",
    "\n",
    "    score = 0\n",
    "    \n",
    "    # Remove the trailing empty ngram if necessary\n",
    "    if len(ngrams[-1]) == 0:\n",
    "        ngrams = ngrams[:-1]\n",
    "\n",
    "    for ngram in ngrams:\n",
    "        value = 1\n",
    "\n",
    "        for word in ngram:\n",
    "            if word in modifiers:\n",
    "                value *= modifiers[word]\n",
    "            elif word in valence:\n",
    "                value *= valence[word]\n",
    "\n",
    "        if verbose:\n",
    "            print(ngram, value)\n",
    "\n",
    "        score += value\n",
    "\n",
    "    return score/len(ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation is still relatively simple, but, as you can see, the results are already better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretty', 'annoying'] -1.5\n",
      "['hate'] -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_modified(texts[1], valence, modifiers, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complete implementation would be more careful in handling the modifiers and would build larger ngrams so that cases like this one would also work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'very', 'good'] -1.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_modified(\"It was not very good\", valence, modifiers, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And even more complex (and unrealistic) examples work fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'not', 'very', 'very', 'good'] 2.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_modified(\"It was not not very very good\", valence, modifiers, True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
